# ================================================
# EGMC:Explainability using Gradient based methods for Modulation Classification
# ================================================
## Student Name: Tejas Gaikwad
## Instructor: Dr. Richa Singh
## Institute : Indian Institute of Technology Jodhpur
## Reseach Area : Applications of Machine Learning in Communication/ Telecommuniation Fields
## ================================================================
## Abstract—Over the last decade, Convolutional Neural Network (CNN) models are being used and have been successful in solving the problems which seemed complex to the former models.
These deep models are considered as the ”black box” because of the lack of understanding of their internal functioning. It gets more and more difficult as the complexity of the network
increases. There has been a significant research going on in developing the explainability methods for the deep learning models to understand the learned parameters and predictions
reasoning. This article gives a ignite the idea of explainability and visualisation aspect in the field of communication. 

****NOTE : MAIN aim for this project is to propose explainability instead of having any accurate model to predict

Index Terms—Visualisation, Constellation Diagram, Modulation Classification

Procedure to Run the Code

This code was run on Kaggle(similar to Jupyter Notebook). So, any Jupyter based editor would be fine to run the code

* Step 1: Extract the file Dataset
#below step would require just running the cells
* Step 2: Convert the files into 2D images 
* Step 3: Pre-process the image(Resizing, dimention expansion, normalising)
* Step 4: Fit the model and evaluate the performance 
* Step 5: Then select the layer you want to visualise
* Step 6: Run Gradcam plusplus cell to visualise the output

