===============================================================================================================================
	EGMC:Explainability using Gradient based methods for Modulation Classification
===============================================================================================================================		
				Dependable Artificial Intelligence | Project
Student Name: Tejas Gaikwad
Instructor: Dr. Richa Singh
Institute : Indian Institute of Technology Jodhpur
Reseach Area : Applications of Machine Learning in Communication/ Telecommuniation Fields
================================================================================================================================
Abstract—Over the last decade, Convolutional Neural Network (CNN) models are being used and have been successful in solving the problems which seemed complex to the former models.
These deep models are considered as the ”black box” because of the lack of understanding of their internal functioning. It gets more and more difficult as the complexity of the network
increases. There has been a significant research going on in developing the explainability methods for the deep learning models to understand the learned parameters and predictions
reasoning. This article gives a ignite the idea of explainability and visualisation aspect in the field of communication. 

****NOTE : MAIN aim for this project is to propose explainability instead of having any accurate model to predict

Index Terms—Visualisation, Constellation Diagram, Modulation Classification

Procedure to Run the Code

This code was run on Kaggle(similar to Jupyter Notebook). So, any Jupyter based editor would be fine to run the code

Step 1: Extract the file Dataset
#below step would require just running the cells
Step 2: Convert the files into 2D images 
Step 3: Pre-process the image(Resizing, dimention expansion, normalising)
Step 4: Fit the model and evaluate the performance 
Step 5: Then select the layer you want to visualise
Step 6: Run Gradcam plusplus cell to visualise the output

